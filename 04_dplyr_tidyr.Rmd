---
title: "Working With Data in dplyr and tidyr"
author: "Kim Cressman"
<<<<<<< HEAD:04_dplyr_tidyr_2.Rmd
output: 
    html_document:
        toc: true
        toc_depth: 3
        toc_float:
            collapsed: false
=======
date: "10/8/2019"
output: html_document
>>>>>>> 7a8c674e66d1cefa0ad40e76d4b40a6423283729:04_dplyr_tidyr.Rmd
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(tidyr)
library(here)
library(ggplot2)
```


Sometimes, the data we're working with is not quite ready for whatever it is we want to do. We may need to summarize the data based on some group, calculate additional parameters, subset the data, or even completely reshape it. The packages `dplyr` and `tidyr` can help with these tasks!  

# dplyr verbs, using ebird data  

First, let's read in the ebird data and remind ourselves what's in it:  

```{r}
ebird <- read.csv(here::here("data", "eBird_workshop.csv"), stringsAsFactors = FALSE)
glimpse(ebird)   # 183,742 rows
```



We may not talk about this, but there are (presumably accidentally) duplicate rows in this data frame. We can see them with:  

```{r}
janitor::get_dupes(ebird)   # 22 duplicates = 11 that need to go
```

They are exact copies of other rows, not any data entry problems (although `janitor::get_dupes()` is very helpful in finding errors like mis-typing a site name), so we'll just get rid of them by using `dplyr::distinct()` to keep only unique rows.  

```{r}
ebird <- dplyr::distinct(ebird)
glimpse(ebird)   # 183,731 rows
```




## Choose _rows_: `filter()`  

This has a lot of rows. We might only be interested in observations about a single bird species, or from a single state, which means we want to choose rows. To do this, we use the verb `filter()`:  

```{r}
ebird_AK <- ebird %>% 
        filter(state == "AK")
# equivalent to: filter(ebird, state == "AK")
glimpse(ebird_AK)
```

Notice a couple things here:  

+  We use `==` to specify an exact condition. If we were working with numbers, we could use:  
    +  `<`  
    +  `<=`  
    +  `==`  
    +  `!=` (**not** equal to)  
    +  `>=`  
    +  `>`  
+  The condition specified inside `filter()` MUST return either true or false, for each row.  


### multiple conditions  

We can filter based on more than one criterion, e.g. if we want all birds from Alaska, but only in the year 2008:  

```{r}
ebird_AK_2008 <- ebird %>% 
        filter(state == "AK",
               year == 2008)
glimpse(ebird_AK_2008)
```


**Note**: It doesn't matter if you select `state` or `year` first - you can do either.  

Because we're just experimenting with filtering here, and don't really need to save these as data frames in our environment, I'm going to stop assigning to objects and start doing this:  

```{r}
ebird %>% 
        filter(state == "AK",
               year == 2008) %>% 
        glimpse()
```

Note, that's not something you want to do if you actually need to work with the data frame later!  

***

### mini-challenge 1  

How could we pull out birds in Alaska (AK), before 2010? (Hint: you can use the same symbols on year that you would use with any other numbers)  

```{r}

```

***  

### multiple conditions, cont.  

What if we want to look at birds from more than one state? There are a few ways to do this. 

Perhaps the easiest is to make a vector of the states you're interested in:  

```{r}
my_states <- c("AK", "AL", "MS")
```

And then use `%in%` in the filter statement, to say, e.g. "any of the states _in_ this vector": 
```{r}
ebird_mystates <- ebird %>% 
        filter(year == 2008,
               state %in% my_states) %>% 
        glimpse()
# make sure the states we named, and only the states we named, are represented:
unique(ebird_mystates$state)
```

You could also skip the step of naming the vector separately:  

```{r}
ebird %>% 
        filter(year == 2008,
               state %in% c("AK", "AL", "MS")) %>% 
        glimpse()
```


### mini-challenge 2  

How would you filter the data to contain only the species "American Coot" from MS and FL (your instructors' states), in all years *except* 2010? Assign this object to a data frame and verify (using `unique()`) that you did it right.    

```{r}

```


***
***


## Choose _columns_: `select()`  

When you're working with a lot of data, you may not want or need to keep all the columns you started with. In this case, `select()` is what you need.

The ebird data frame doesn't have too many columns, but that makes it easy to see exactly what we're doing! Let's pretend we only want to keep species, state, and year. We can do this two ways:  

First, by selecting the columns we **do** want to keep:  

```{r}
ebird %>% 
        select(species, state, year) %>% 
        glimpse()
```


Or second, by using a `-` in front of the columns we **don't** want to keep:  

```{r}
ebird %>% 
        select(-samplesize, -presence) %>% 
        glimpse()
```

Either of these can be really handy depending on what your original data frame looks like and what you're trying to do!  


Order **does** matter in `select()`; remember it didn't matter in `filter()`. In `select()`, selections are made in the order specified - so if you want to rearrange the columns of your data, you can do it with this command!  

```{r}
ebird %>% 
        select(year, state, species) %>% 
        glimpse()
```


You can also move just one or a few columns to the beginning by specifying it/them, and then `everything()` - it keeps all other columns, in their original order:  

```{r}
ebird %>% 
        select(year, everything()) %>% 
        glimpse()
```


### helper functions  

Sometimes you have a lot of columns that start with the same prefix, or that end with the same appended matter; maybe you want to keep all of them (or get rid of all of them). In these situations, you can use the helper functions `starts_with()` and `ends_with()`. See the `dplyr` cheatsheet for other possible helper functions.  

In our little example, let's keep columns whose names start with 's':  

```{r}
ebird %>% 
        select(starts_with("s")) %>% 
        glimpse()
```

Or columns that end with 'e':  

```{r}
ebird %>% 
        select(ends_with("e")) %>% 
        glimpse()
```



### mini-challenge 3  

From the ebird data, subset to only include the species American Coot, from the states FL, AL, and MS. Keep only the state, year, and presence columns. What is the proper order of operations in this case?  

```{r}

```


***  
***  

## Setup for the next bit of the workshop  

We're going to switch datasets here, to one that's a little more complicated: water quality data! Shannon has downloaded monitoring data from several National Estuarine Research Reserves for the year 2016, and has already winnowed it down a bit to daily averages of several parameters that we measure. We will use your newfound `select()` and `filter()` skills to make it an even smaller data frame, and then we'll learn how to calculate new columns and do some group-wise summaries.  

```{r}
wq <- read.csv(here::here("data", "daily_wq.csv"), stringsAsFactors = FALSE)
glimpse(wq)
```


### mini-challenge 4  

Because this is so important, I will provide working code in a chunk below. But please attempt it yourself first!!!  

We have read in the daily water quality data for a few stations. Create a new data frame called `wq_trimmed` where, from `wq`, you:    

+  **Select** the following columns:  station_code, month, dat, temp, sal, do_pct, and depth.  
+  **Filter** for rows where `depth` is *not* missing. (Hint: `is.na` is the function that checks to see if a value *is* missing. How would you look for "not" `is.na`?   It's similar to "not equal to" from above.)

```{r}

```




How much has been removed from the data frame?  

```{r}
dim(wq)
dim(wq_trimmed)

# can subtract both rows and columns at once!
dim(wq) - dim(wq_trimmed)

# why did all those rows go away?
# note: wrapping an entire piece of code in parentheses both
# saves the object AND prints it to screen
(stns_all <- unique(wq$station_code))
(stns_trimmed <- unique(wq_trimmed$station_code))

# here's how to find the station code that's in one and not the other
# start by asking, for each value in stns_all, "is this in stns_trimmed?":
stns_all %in% stns_trimmed

# note that returned logical values
# we want to know which station returned FALSE
# so we select - which is actually easier to do in base R than tidyverse
# but the syntax can be tough to wrap your head around
stns_all[!(stns_all %in% stns_trimmed)]
```


Some SWMP stations report `depth`, which is water depth above the data logger; and others report `level`, which is water surface relative to a standard datum (NAVD88). There is an important distinction that's irrelevant for what we want to cover today, so here we have only kept the stations that report `depth`.  




### mini-challenge 4 answer   

Last chance to try it yourself.... 
but if you didn't get it to work, run this chunk:  

```{r}
wq_trimmed <- wq %>% 
    select(station_code, month, day, temp, sal, do_pct, depth) %>% 
    filter(!is.na(depth))
```



## Modifying data frames with `mutate()`  


It's easy to make a new variable out of other variables in the data frame using `mutate()`. This operates on rows. Say we want to talk about water depth (or make a graph!) to the public - we might want to change the units from meters to feet. That's simple multiplication! So here, we'll add a column to the data frame.      

```{r}
wq_trimmed <- wq_trimmed %>% 
    mutate(depth_ft = depth * 3.28)
View(wq_trimmed)
```


You can also use other columns. You can use them in mathematical expressions, or just combine them:        

```{r}
wq_trimmed <- wq_trimmed %>% 
    mutate(monthday = paste(month, day, sep = "-"),
           meaningless_thing = sal + temp)
View(wq_trimmed)
```


You can even use a column immediately after creating it!  

```{r}
wq_trimmed %>% 
    mutate(monthday = paste(month, day, sep = "-"),
           meaningless_thing = sal + temp,
           even_more_meaningless_thing = meaningless_thing + 5) %>% 
    View()
```



### mini-challenge 5  

There are two parts to this. You can approach them separately or within the same series of pipes. Remember to save the result as the new, better, `wq_trimmed` data frame!   

1.  Now that we've started creating more columns, it might make sense to get rid of some old ones. Remove `monthday` and `meaningless_thing` from the `wq_trimmed` data frame.  
1.  The same person that wants to see `depth` in feet rather than meters *also* wants you to turn `temp` into Fahrenheit, from Celsius. You've looked up the conversion. Now create a new column, `temp_f`, with the new variable.   **F = (9/5)(temp in C) + 32**


As with mini-challenge 4, the answer is below. No peeking!  


```{r}

```










### mini-challenge 5 answer  

```{r}
wq_trimmed <- wq_trimmed %>% 
    select(-monthday, -meaningless_thing) %>% 
    mutate(temp_f = (9/5) * temp + 32)
View(wq_trimmed)
```


<<<<<<< HEAD:04_dplyr_tidyr_2.Rmd
# Group-wise operations with `group_by()` and `summarize()`  
=======


# FEELS LIKE BREAK TIME  

If making a graph relaxes you, make a scatterplot of `depth` by `depth_ft` and reassure yourself that the points fall on a line. Play with other options too, to make the graph as pretty (or as ugly) as you like! 

```{r}

```





***  
*** 

## Group-wise operations with `group_by()` and `summarize()`  
>>>>>>> 7a8c674e66d1cefa0ad40e76d4b40a6423283729:04_dplyr_tidyr.Rmd

Say we want to find out how many birds were seen by state in the ebird dataset. We can do that. These operations are also great for lumping data into daily, monthly, or yearly averages, which we'll do on the SWMP dataset.    

```{r}
ebird %>% 
    group_by(state) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    glimpse()
```



We can also group by combinations of multiple variables:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    glimpse()
```



### mini-challenge 7  

How would you group the `wq_trimmed` dataset to calculate monthly average temperature and salinity, and their standard deviations, at each station?  

```{r}

```











### mini-challenge 7 answer  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize(mean_temp = mean(temp, na.rm = TRUE),
              sd_temp = sd(temp, na.rm = TRUE),
              mean_sal = mean(sal, na.rm = TRUE),
              sd_sal = sd(sal, na.rm = TRUE)) %>% 
    View()
```



There are a couple of useful variants of `summarize` for special cases. Note that you can only perform one summary function with these (so you couldn't calculate mean *and* standard deviation in this way).    

#### `summarize_all()`  

Applies a function to all of the non-grouping variables! (Even "day", which isn't meaningful, but that's okay)  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize_all(mean, na.rm = TRUE) %>% 
    View()
```


#### `summarize_at()`  

To choose which variables to summarize  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize_at(c("temp", "sal"), mean, na.rm = TRUE) %>% 
    View()
```




# Sort  


You can also sort your data frame (or its summary) using `arrange()`. Let's put our ebird summary in order by species, then state:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    arrange(species, state) %>% 
    View()
```


Or put it in order by `max_presence`:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    arrange(max_presence) %>% 
    View()
```


To go from highest to lowest instead, use `desc()`:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    arrange(desc(max_presence)) %>% 
    View()
```




### mini-challenge 8  

Use the `wq_trimmed` data frame. Calculate monthly average temp, sal, and do_pct (at least - more variables if you like) for each station. Make a scatterplot using any two of these variables. Use what you've learned about `ggplot2`'s options to adjust the look and feel of the graph. Is the relationship what you expected it to be? Does it vary by site?     

```{r}

```













Here's one possible way to go about it. You could also make a new data frame of the summary variables, and use that in a separate call to `ggplot` - which might be a better way to do it, especially if you'll want to make more than just one graph using that same information.  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize_all(mean, na.rm = TRUE) %>% 
    ggplot() +
    geom_point(aes(x = sal, y = do_pct, col = station_code), 
               size = 3, alpha = 0.3) +
    theme_minimal() +
    facet_wrap(~station_code)
```


***  
***  
***  

# Moving data around with `tidyr`  

# PROBABLY WORTH TALKING ABOUT TIDY DATA GENERALLY AND HADLEY'S PAPER  

The two major functions in `tidyr` are `pivot_longer()` to make your data frame tall and narrow, and `pivot_wider()` to make it shorter and wider. If you've ever heard of/used `gather()` and `spread()`, these are newer, better versions. `gather()` and `spread()` won't go away, but they are deprecated - no longer under active development. It is best to start using the new `pivot` functions moving forward.    

Very often, wide data is the most readable for people. Here is an example:  

# INSERT EXAMPLE OF WIDE DATA  

Good example! C_elegans_tox.csv - a portion of a spreadsheet from Boyd et al., 2015
# look up this citation and link to download data  
in which they compiled toxicity effects of various chemicals on the worm *C. elegans*.  

Let's first take a look at the file:  

```{r}
tox <- read.csv(here::here("data", "C_elegans_tox.csv"), stringsAsFactors = FALSE)
View(tox)
```


This spreadsheet was originally in Excel, and had the $\mu$ symbol for micro-molar. That turned into a `?` when it was saved as csv, and here upon being read in, it just became a period. So most of these columns that end in `.M` should be interpreted as micromolar.  


We'll subset to just the portion that we might want to re-shape, which is the columns that include concentration in the column name. We'll also clean names along the way.  

```{r}
tox_cleaned <- tox %>% 
    janitor::clean_names() %>% 
    select(1:10)


tox_cleaned2 <- tox[1:12, 1:10]   # just pull out the first 12 chemicals to make this dataset more manageable
```


We want to do a few things here: we want a single column for the value of mean *C. elegans* response, and we want to extract the concentrations from the column names and turn them into a variable that we'll call "conc".  

Let's start without worrying about messing with the column names. This is the format we'd use. If we didn't have so many columns to pivot, we could use the column names.  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = 4:10, names_to = "conc", values_to = "response")
```


We can get rid of common prefixes by using `names_prefix`:  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = 4:10, names_to = "conc", values_to = "response",
                 names_prefix = "c_elegans_mean_response")
```


We could also select the columns to pivot by what they start with:  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = starts_with("c_elegans_mean_response"), names_to = "conc", values_to = "response")
```


And we can separate the column as we pivot it:  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = starts_with("c_elegans_mean_response"), 
                 names_to = c("org_genus", "org_species", "type", "var", "conc1", "conc2", "units"),
                 names_sep = "_",
                 values_to = "response")
```




```{r}
tox_long <- tox_cleaned2 %>% 
    pivot_longer(cols = starts_with("C.elegans.mean.response"),
                 names_to = c("prefix","conc","units"),
                 names_sep = "\\.\\.",
                 values_to = "response") %>% 
    mutate(conc = as.numeric(conc))


ggplot(tox_long) +
    geom_point(aes(x = conc, y = response, color = Name), size = 3)

p <- ggplot(tox_long) +
    geom_point(aes(x = conc, y = response, color = Name), size = 3)

p +
    facet_wrap(~Name)

p +
    facet_wrap(~Name) +
    scale_x_log10()


p +
    facet_wrap(~Name) +
    scale_x_log10() +
    theme_bw() +
    labs(title = "Toxicity curves for C. elegans",
         x = "log of concentration (uM)",
         y = "response",
         color = "Chemical name")


# or remove the legend:
p +
    facet_wrap(~Name) +
    scale_x_log10() +
    theme_bw() +
    labs(title = "Toxicity curves for C. elegans",
         x = "log of concentration (uM)",
         y = "response") +
    theme(legend.position = "none")
```




### end  




From Chapter 9 of *The Statistical Sleuth*, 2nd edition, by Ramsey and Schafer. Original data from Huey et al., "Rapid Evolution of a Geographic Cline in Size in an Introduced Fly", *Science* 287 (2000): 308-309.  

These are mean and standard errors of log-transformed wing length in invasive flies. The data has been aggregated and summarized for presentation; we are looking at grouped values.    

```{r}
flies_wide <- read.csv(here::here("data", "flies.csv"), stringsAsFactors = FALSE)
glimpse(flies_wide)
```

We will simplify this a bit to make it easier to learn pivoting.

```{r}
flies <- flies_wide %>% 
    select(Continent, 
           Latitude,
           Female = Female.mean,     # renaming as I select
           Male = Male.mean)
glimpse(flies)
```

In this data set, wing lengths were measured in both female and male flies. Sex is actually a variable, and we can work with the data a little more easily if we make it a column. So we will `pivot_longer()`.  

```{r}
flies_long <- pivot_longer(flies, cols = c(Female, Male), names_to = "sex", values_to = "wing_length")
glimpse(flies_long)
```

This format makes it easier to plot in different ways, or calculate different types of averages. Let's start with some plots.  


```{r}
ggplot(flies_long) +
    geom_point(aes(y = Latitude, x = wing_length), 
               size = 3)
```

Hmmm, looks like we have two different size classes. Could that be related to sex? Let's color by sex (remember, because this is showing something in the data, it goes inside `aes()`):    

```{r}
ggplot(flies_long) +
    geom_point(aes(y = Latitude, x = wing_length, col = sex), 
               size = 3)
```

We may also be curious about whether continent plays a role, and we can represent that by shape.  

```{r}
ggplot(flies_long) +
    geom_point(aes(y = Latitude, x = wing_length, col = sex, shape = Continent), 
               size = 3)
```

Alternately, we could use shape for sex and color for continent.  

When it comes to grouping and summarizing data, tidy data is also easier to use. We will continue to work with the simplified data for a moment. 

Let's say we want to find the average wing length by sex, by continent. That's doable with appropriate subsetting in the original data frame, but it's even easier here:  

```{r}
flies_long %>% 
    group_by(Continent, sex) %>% 
    summarize(mean = mean(wing_length, na.rm = TRUE))
```


And if we simply want the mean by continent, disregarding sex (which may not be the best thing to do, but bear with me), that's exactly as easy:  

```{r}
flies_long %>% 
    group_by(Continent) %>% 
    summarize(mean = mean(wing_length, na.rm = TRUE))
```


#### not really a challenge  

How would you find those averages from the original `flies` data frame?  

```{r}
# it's easy to generate an overall average by sex, but grouping by continent 
# in the original context is tougher
```

You can get more complicated too, by using `pivot_longer_spec()` if you want to keep, e.g., all of the standard error and ratio columns too. Check out `vignette("pivot")` for more details.


The opposite of `pivot_longer()` is `pivot_wider()`. Sometimes you have one observation split over multiple rows, like in a dataset we'll see shortly, and you want to make certain variables be their own columns. To learn how it works, we'll first widen the fly dataset back out, and then work on a slightly more complicated dataset.  

```{r}
flies_wide2 <- flies_long %>% 
    pivot_wider(names_from = sex, values_from = wing_length)
View(flies_wide2)
```


Now let's look at a dataset that has some more going on.  

```{r}
gtmnut <- read.csv(here::here("data", "GTM_2019nutrients.csv"), stringsAsFactors = FALSE)
View(gtmnut)
```

This is how Shannon gets her nutrient measurements back from her lab. There is metadata on every row, with every nutrient. This can be very useful! But it can also make it hard to work with the data. So what we'll do is select only the columns we need: station, sample date, nutrient component, and value. Then we'll pivot it out so that each nutrient value is in its own column.  

```{r}
# also do some renaming along the way
gtmnut_trimmed <- gtmnut %>% 
    select(station = StationCode,
           datetime = DateSampled,
           nutrient = ComponentLong,
           value = Result)
View(gtmnut_trimmed)
```

Each sample spans many rows! We'll spread that out so each sample only takes up one row.  

```{r}
gtmnut_wide <- gtmnut_trimmed %>% 
    pivot_wider(names_from = nutrient,
                values_from = value)
View(gtmnut_wide)
```


As you can see, we now have a LOT of columns, and there are special characters in their names. We'll start by cleaning up the names (remember this `janitor::clean_names()` function?), and then select only a few primary nutrients to work with.  

```{r}
gtmnut_wide <- janitor::clean_names(gtmnut_wide)
View(gtmnut_wide)

gtmnut_wide_trimmed <- gtmnut_wide %>% 
    select(station, datetime, 
           po4 = o_phosphate_p, 
           nox = no2no3_n, 
           fecal_coliform = fecal_coliforms_membrane_filter,
           tss,
           nh4 = ammonia_n,
           total_p,
           chla = chlorophyll_a_corrected)
View(gtmnut_wide_trimmed)
```



#### end  

But to work well with R (and many other languages and analytical software), it is actually better for data to be in a "long" format:  

# INSERT EXAMPLE OF LONG DATA  

SHANNON'S nutrient data that they get back from the lab! Sometimes your data is *too* long, and every observation is split over multiple rows for various reasons. To work with it, we want to give each nutrient its own column (and do something else with all the associated metadata like MDL etc., but that's beyond the scope).    

## long-to-wide  

The data sets we've been using are in a long format. Can you picture a more readable way to present some of this ebird data? Maybe a column for each state, a row for each species/year combination, and presence in the main cells of the table? We can do that, fairly easily.  

```{r}
ebird_wide2 <- ebird %>% 
    select(-samplesize) %>% 
    pivot_wider(names_from = state,
                values_from = presence)

ebird_wide2 %>% 
    arrange(species, year) %>% 
    View()
```


### mini-challenge 6  

You can make a more bite-sized table by filtering to a single species, state, or year of interest. Try making a table of American Coot presence in AL, FL, and MS. Give each state its own column, and each year its own row. (There is more than one way to do this, so compare your answer to your neighbors! Hint: you can use `select()` and/or `filter()` at the beginning of a pipe, and pivot_wider at the end.)    

```{r}

```


## wide-to-long  

What you'll encounter more often is getting data in a wide format, and needing to narrow it. The function for this is `pivot_longer()`. It's similar to `pivot_wider()`.   
