---
title: "Functions and Loops"
author: "Kim Cressman"
date: "9/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Additional resources to help teach this:
Software Carpentry, Programming with R: 
for loops:  http://swcarpentry.github.io/r-novice-inflammation/03-loops-R/index.html  

whole lesson: http://swcarpentry.github.io/r-novice-inflammation/

Setup:

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(tidyr)
library(here)
library(stringr)
library(ggplot2)
```

```{r}
ebird <- read.csv(here::here("data", "eBird_workshop.csv"), stringsAsFactors = FALSE)
ebird <- dplyr::distinct(ebird)

wq <- read.csv(here::here("data", "daily_wq.csv"), stringsAsFactors = FALSE)
wq_trimmed <- wq %>%
    select(station_code, month, day, temp, sal, do_pct, depth) %>%
    filter(!is.na(depth)) %>%
    mutate(depth_ft = depth * 3.28,
           temp_f = (9/5) * temp + 32)
```


# Functions  

Starting with this because most of the time, a function will solve your problems.  

There is a principle in programming known as **DRY** - **D**on't **R**epeat **Y**ourself.  

I'm not here to shame you for copying-and-pasting, then making a little change to, code that works. We all do that.  

However. If you've used the same chunk of code more than 3 times, you may want to consider writing a *function*. This can reduce errors due to typos (or just forgetting to change something in some spot), and also makes it easier to re-run a whole pile of code when you realize something needed to change - you only have to change it in one place!    

## Outline of a function  

You've got some **working code** that gives you an **output** you want. And you identify the **pieces that you want to change**. These bold parts are the three parts of a function:  

1.  your working code is the **body**.  
2.  the output is known as the **return value**. It can be a single value, or a data frame, or a list.... whatever you want it to be.  
3.  the part(s) that you change are the **arguments** (also known as "formals").  
    +  some advice from Hadley Wickham and Garrett Grolemund, in ["R for Data Science"](https://r4ds.had.co.nz/) (aka *R4DS*):  
    +  put *data* arguments first  
    +  *detail* arguments should go at the end, and should usually have default values

You also need to be aware of the **environment** in which you call the function. Again from R4DS: "The environment of a function controls how R finds the value asociated with a name." We will come back to this a little later when you've seen the structure of a function - but essentially what it means is, if you use some variable in your function but don't make it an argument, R is going to look "upstream" from your function and try to find something with that name.  


## Function Example  

R has functions to calculate mean and standard deviation of a dataset, but there isn't one for standard error. Remember, `standard error = sd / sqrt(n)`. 

Let's get this working on a small chunk of data. I like to pull out a little bit and call it "test".   

```{r}
test <- wq_trimmed %>% 
  filter(station_code == "gndblwq   ",
         month == 1)  # there are some trailing white spaces in the station codes  

glimpse(test)


# let's build up to it:  

# stdev:
sd(test$temp_f, na.rm = TRUE)

# sample size:  
length(test$temp_f)

# what if there were NAs though? remove them:
# have to use "sum" because we're switching to a logical
sum(!is.na(test$temp_f))
```


#### Aside that we won't go through in the workshop  

I figured out the `sum(!is.na(etc))` part the hard way, btw - that's often the toughest part of a function - getting the code to do what you want it to. For reference, here are my steps (the code here won't be evaluated when this document is knitted). Some of these worked, and some of them didn't.    

```{r, eval = FALSE}
length(test$temp_f, na.rm = TRUE) 
# R doesn't like that argument at all

# does this work?
length(!is.na(test$temp_f))
# well.... maybe. it does return a number.


# let's create a smaller dataset and introduce some NAs to make sure
test2 <- test$temp_f
test2[2:3] <- NA  


length(!is.na(test2))  
# 31 isn't the answer I want to see, so something is wrong
# length is simply returning how long the vector is, inclusive of NAs

# !is.na returns a "true" or "false".
# "true"/"false" are also seen as "1"/"0", and we can add:
sum(!is.na(test2))  
# and that gave me what I wanted to see
```


#### end of aside  



```{r}
# so combine those for standard error, and don't forget the `sqrt`:
sd(test$temp_f, na.rm = TRUE) / sqrt( sum(!is.na(test$temp_f)) )
```


See why that might be annoying to type over and over again? And how it could be prone to error?  


Okay, so what can we generalize here? What are we repeating?  














`test$temp_f`, right?  


So let's assign that to something, and replace the specific value in our code with the variable `x`:  

```{r}
x <- test$temp_f
sd(x, na.rm = TRUE) / sqrt( sum(!is.na(x)) )
```


Now we could make another variable our `x` and find its standard error.  

```{r}
x <- test$sal
sd(x, na.rm = TRUE) / sqrt( sum(!is.na(x)) )
```



We're still copying and pasting, but it's general. So we're most of the way to the function. We need to wrap it up like this, in `()` and `{}`, and come up with a name:  

```{r}
sterr <- function(x){
  sd(x, na.rm = TRUE) / sqrt( sum(!is.na(x)) )
}
```

Run the above chunk of code. Now you can see `sterr` in your Environment pane as a function!  And you use it like any other function:  

```{r}
sterr(test$temp_f)
sterr(test$do_pct)
```


Let's check it on our bigger data frame!  

```{r}
sterr(wq_trimmed$temp_f)
```

### mini-challenge  

Use `group_by`, `summarize`, and our new `sterr` function to generate a table of standard error by month, by station, for `temp_f`. Does the standard error at `gndblwq` for January (month 1) match our output from above?    

```{r}

```






















```{r}
wq_trimmed %>% 
  group_by(station_code, month) %>% 
  summarize(temp_f_sterr = sterr(temp_f))
```



### (not-so-) mini-challenge  

Now **you** write a function! Name it `divide_by_10`. The input should be a vector (like we did with `sterr`), and the output should be each value of that vector divided by 10.  

Remember to get it working *before* you wrap it up into a function.  

```{r}

```


























```{r}
test$sal / 10

divide_by_10 <- function(x){
  x/10
}

divide_by_10(test$sal)
```


### mini-challenge 3?   


Now. What if we want to divide by something other than 10? Generalize the function to take two arguments as input. The second input (call it `y`) should be the denominator in your `divide_by` function.  

```{r}

```

















Did you get this?  

```{r}
test$sal / 10

divide_by <- function(x, y){
  x / y
}

divide_by(test$sal, 10)
divide_by(test$sal, 100)
```

It's always a good idea to make sure you get output you expect!  


## Setting default values for arguments  

So, once you have a working function, you can continue to build on it and make it more flexible. 

The next thing we'll do is set a default argument for `y` - if nothing else is specified, our function will divide the input vector by 10. This is done in the argument definition:  

```{r}
divide_by <- function(x, y = 10){
  x / y
}

divide_by(test$sal, 10)
divide_by(test$sal, 100)
divide_by(test$sal)
```


Remember, it's a good idea to put the *data* argument first.





### mini-challenge  

Change the names of the arguments in this function from `x` and `y` to `num` (to represent numerator) and `denom` (for denominator). Make sure it still works.

```{r}
divide_by <- function(x, y = 10){
  x / y
}

divide_by(test$sal, 10)
divide_by(test$sal, 100)
divide_by(test$sal)
```



## Other function testing  

What do you think will happen if we run these lines of code?  

```{r, eval = FALSE}

divide_by(test$sal, "a")

divide_by(test$sal, TRUE)

divide_by(test$station_code, 10)
```


We've been checking all along to make sure we get output we expect in simple cases. It's also a good idea to see what will happen if you feed your function something you *shouldn't* and make sure it fails. Notice that it did *not* fail when we tried to divide by "TRUE" - that's because R sees TRUE as 1 and FALSE as 0. We might want it to fail in this case!

```{r, eval = FALSE}
divide_by <- function(num, denom = 10){
  stopifnot(is.numeric(num), is.numeric(denom))
  num / denom
}

# things that should work
divide_by(test$sal, 10)
divide_by(test$sal, 100)
divide_by(test$sal, test$do_pct)
divide_by(test$sal)
divide_by(denom = 100, num = test$sal)

# things that should fail
divide_by(test$sal, "a")
divide_by(test$sal, TRUE)
divide_by(test$station_code, 10)
```


# Functions using graphs  

What we've done so far today has been very tidyverse-heavy. The tidyverse reduces the cognitive burden when it comes to interactively exploring and analyzing data. However, it does make it a bit more difficult to program. We won't go into details today, but we will go over some "cheats" to make it easy to take a graph that you like and turn it into a function.  

First we'll make a simple plot. I'm not claiming that this is pretty.  

```{r}
ggplot(wq_trimmed) +
  geom_point(aes(x = sal, y = do_pct, col = station_code))
```


Say we want to make this plot for a variety of pairs of parameters, and our data frame may not always be called `wq_trimmmed`. So these are three arguments that we want to be able to specify. When we use RStudio's menu to extract a function, it gives us four - it includes station_code, and looks like this:    

```{r}
my_plot <- function(wq_trimmed, sal, do_pct, station_code) {
  ggplot(wq_trimmed) +
    geom_point(aes(x = sal, y = do_pct, col = station_code))
}
```


So let's change some names and see what happens.  

```{r}
my_plot <- function(data, param1, param2, param3) {
  ggplot(data) +
    geom_point(aes(x = param1, y = param2, col = param3))
}
```

Let's see what happens when we try.....

```{r, eval = FALSE}
my_plot(wq_trimmed, sal, do_pct, station_code)
```


Working interactively in the tidyverse is easy because it bypasses some of the rules that R uses to associate function arguments with names in the data. This makes it a bit trickier to use some of our favorite tidyverse functions inside functions that we write. Recently, however, they made it easier to deal with this problem; and now we need to simply wrap the arguments that will change inside two curly braces `{{ }}`.
```{r}
my_plot <- function(data, param1, param2, param3) {
  ggplot(data) +
    geom_point(aes(x = {{param1}}, y = {{param2}}, col = {{param3}})) 
}

my_plot(wq_trimmed, sal, do_pct, station_code)
my_plot(wq_trimmed, sal, do_pct, month)  # we may want to go up into our function
# and specify that we want to turn the "col" argument into a factor

# try it yourself!  
```

If in doubt, wrap it in "curly curly" `{{ }}`.



#### Aside  

Note that to facet, it's not quite as simple, and you have to use `var( {{ }} )`, without the `~`, inside your function. I don't know why, but this answer in the [RStudio Community forum](https://community.rstudio.com/t/problem-with-facet-wrap-and-curly-curly/36975) helped me figure it out.  

```{r}
my_plot <- function(data, param1, param2, param3) {
  ggplot(data) +
    geom_point(aes(x = {{param1}}, y = {{param2}}, col = factor({{param3}}))) +
    facet_wrap(vars( {{param3}} ))
}

my_plot(wq_trimmed, sal, do_pct, station_code)
my_plot(wq_trimmed, sal, do_pct, month)
```


#### end aside


### mini-challenge  

# ?????   



```{r, eval = FALSE}
# here's my entire functions and loops script from TTW 2019

  
library(SWMPr)
library(lubridate)
library(ggplot2)

# if you need to re-read the data:

# data_path <- "data/AQS_zip"
# bhwq <- import_local(data_path, "gndbhwq", trace = TRUE)
# bhwq_qaqc <- qaqc(bhwq)
# met_data <- import_local(data_path, "gndcrmet", trace = TRUE)
# met_qc <- qaqc(met_data, qaqc_keep = c(0, 1, 4, 5))



### A brief introduction to functions and for loops



### When you copy and paste code a lot, only changing one or two things,
### you probably want to make a function or run a loop


### For loops ----

## Will start with loops because I'm going to go into less depth on them
# the idea is, you have some set of things that you want to iterate over

#  for each _____, do ______

# for example, you want to perform some action for each of your monitoring stations
# the status reports work this way
# so do the QA/QC scripts



# typically we use the letter "i" as the index
# for (i in some_set_of_things) { do something }

stns <- c("gndbhwq", "gndbcwq", "gndblwq", "gndpcwq")

for(i in 1:length(stns)){
        print(stns[i])
}


# another option
for(i in seq_along(stns)){
        print(stns[i])
}


# make sure a loop is working by setting i to something
# and running only the code inside the curly braces, e.g.
i <- 2
print(stns[i])




# there are easier ways to do this, but it's a good example for a loop:
# you want to find out what type of column it is

names(bhwq_qaqc)

for(i in seq_along(names(bhwq_qaqc))){
        col_class <- class(bhwq_qaqc[ , names(bhwq_qaqc[i])])
        print(paste("The column", names(bhwq_qaqc[i]), "is type", col_class))
}




### Challenge

## make a vector of 5 different types of fruit
## make another vector of 5 adjectives to describe the fruit
## write a for loop to print "[fruit type] is [adjective]"


```

