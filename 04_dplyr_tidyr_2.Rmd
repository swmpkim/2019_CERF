---
title: "More with dplyr and tidyr"
author: "Kim Cressman"
output: 
    html_document:
        toc: true
        toc_depth: 3
        toc_float:
            collapsed: false
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(tidyr)
library(here)
library(stringr)
library(ggplot2)
```

If you don't still have the data frames in your environment, run these lines of code (they are also necessary to keep here for the purposes of knitting this document):  

```{r}
ebird <- read.csv(here::here("data", "eBird_workshop.csv"), stringsAsFactors = FALSE)
ebird <- dplyr::distinct(ebird)

wq <- read.csv(here::here("data", "daily_wq.csv"), stringsAsFactors = FALSE)
wq_trimmed <- wq %>%
    select(station_code, month, day, temp, sal, do_pct, depth) %>%
    filter(!is.na(depth)) %>%
    mutate(depth_ft = depth * 3.28,
           temp_f = (9/5) * temp + 32)
```


# Group-wise operations with `group_by()` and `summarize()`  

Say we want to find out how many birds were seen by state in the ebird dataset. We can do that. These operations are also great for lumping data into daily, monthly, or yearly averages, which we'll do on the SWMP dataset.    

```{r}
ebird %>% 
    group_by(state) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    View()
```



We can also group by combinations of multiple variables:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    View()
```



### mini-challenge 7  

How would you group the `wq_trimmed` dataset to calculate monthly average temperature and salinity, and their standard deviations, at each station?  

```{r}

```











### mini-challenge 7 answer  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize(mean_temp = mean(temp, na.rm = TRUE),
              sd_temp = sd(temp, na.rm = TRUE),
              mean_sal = mean(sal, na.rm = TRUE),
              sd_sal = sd(sal, na.rm = TRUE)) %>% 
    View()
```



There are a couple of useful variants of `summarize` for special cases. Note that you can only perform one summary function with these (so you couldn't calculate mean *and* standard deviation in this way).    

#### `summarize_all()`  

Applies a function to all of the non-grouping variables! (Even "day", which isn't meaningful, but that's okay)  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize_all(mean, na.rm = TRUE) %>% 
    View()
```


#### `summarize_at()`  

To choose which variables to summarize  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize_at(c("temp", "sal"), mean, na.rm = TRUE) %>% 
    View()
```




# Sort  


You can also sort your data frame (or its summary) using `arrange()`. Let's put our ebird summary in order by species, then state:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    arrange(species, state) %>% 
    View()
```


Or put it in order by `max_presence`:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    arrange(max_presence) %>% 
    View()
```


If you want the highest number at the top instead, use `desc()`:  

```{r}
ebird %>% 
    group_by(state, species) %>% 
    summarize(mean_presence = mean(presence, na.rm = TRUE),
              max_presence = max(presence, na.rm = TRUE)) %>% 
    arrange(desc(max_presence)) %>% 
    View()
```




### mini-challenge 8  

Use the `wq_trimmed` data frame. Calculate monthly average temp, sal, and do_pct (at least - more variables if you like) for each station. Make a scatterplot using any two of these variables. Use what you've learned about `ggplot2`'s options to adjust the look and feel of the graph. Is the relationship what you expected it to be? Does it vary by site?     

```{r}

```













Here's one possible way to go about it. You could also make a new data frame of the summary variables, and use that in a separate call to `ggplot` - which might be a better way to do it, especially if you'll want to make more than just one graph using that same information.  

```{r}
wq_trimmed %>% 
    group_by(station_code, month) %>% 
    summarize_all(mean, na.rm = TRUE) %>% 
    ggplot() +
    geom_point(aes(x = sal, y = do_pct, col = station_code), 
               size = 3, alpha = 0.3) +
    theme_minimal() +
    facet_wrap(~station_code)
```


***  
***  
***  

# Moving data around with `tidyr`  

# PROBABLY WORTH TALKING ABOUT TIDY DATA GENERALLY AND HADLEY'S PAPER  

The two major functions in `tidyr` are `pivot_longer()` to make your data frame tall and narrow, and `pivot_wider()` to make it shorter and wider. If you've ever heard of/used `gather()` and `spread()`, these are newer, better versions. `gather()` and `spread()` won't go away, but they are *deprecated* - no longer under active development. It is best to start using the new `pivot` functions moving forward. If you *haven't* heard of these functions, you are about to learn a very useful topic.     

Very often, wide data is the most readable for people. Let's look at an example.    


## Background on this dataset  

CITATION:
Boyd WA, Smith MV, Co CA, Pirone JR, Rice JR, Shockley KR, Freedman JH. 2016. Developmental effects of the ToxCast Phase I and II chemicals in Caenorhabditis elegans and corresponding responses in zebrafish, rats, and rabbits. Environ Health Perspect 124:586-593; http://dx.doi.org/10.1289/ehp.1409645.  


CONCLUSIONS:
Here, we present an assay that quantitatively and reliably describes the effects of chemical toxicants on C. elegans growth and development. We found significant overlap in the activity of chemicals in the ToxCast libraries between C. elegans and zebrafish developmental screens. Incorporating C. elegans toxicological assays as part of a battery of in vitro and in vivo assays provides additional information for the development of models to predict a chemical's potential toxicity to humans.


The paper can be found here: https://ehp.niehs.nih.gov/doi/10.1289/ehp.1409645  

And the original spreadsheet can be downloaded from the supplemental materials, here:  https://ehp.niehs.nih.gov/doi/suppl/10.1289/ehp.1409645

It is "ehp.1409645.s002.xlsx" in the zip download.  


## Check out the data  


Let's first take a look at the file. I have already done some cleanup and greatly reduced the number of rows - this file originally had 960 rows! I've only kept the first 20. It's not hard to see why it was stored in this wide format. But for certain purposes, it needs to be rearranged into a longer format, and that can be done with just a few lines of code. (It really blows people's minds when you tell them you can "easily" rearrange so much data.)  


```{r}
tox <- read.csv(here::here("data", "C_elegans_tox.csv"), stringsAsFactors = FALSE) 
View(tox)
```



We'll subset to just the portion that we might want to re-shape, which is the columns that include contain *C. elegans* response and a concentration in the column name.  

```{r}
tox_cleaned <- tox %>% 
    select(1:10)
```


## `pivot_longer()`  

We want to do a few things here: we want a single column for the value of mean *C. elegans* response, and we want to extract the concentrations from the column names and turn them into a variable that we'll call "conc".  

Let's start without worrying about messing with the column names. This is the format we'd use. If we didn't have so many columns to pivot, we could use the column names rather than positions ("4:10").  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = 4:10, names_to = "conc", values_to = "response") %>% 
    View()
```

Think about how we just changed the data frame. This is the key of the `pivot` functions: moving between the shape we started with and the shape we just made. All the other stuff is just details - when you understand the long/wide shapes, you're most of the way to doing what you need.  


### extra options  


We could also select the columns to pivot by what they start with (or end with, or contain):  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = starts_with("C.elegans.mean.response"), 
                 names_to = "conc", 
                 values_to = "response")
```



We can get rid of common prefixes by using `names_prefix`:  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = 4:10, 
                 names_to = "conc", 
                 values_to = "response",
                 names_prefix = "C.elegans.mean.response")
```


Or, if we wanted to keep that prefix but in a separate column, we can separate the column as we pivot it. 

In this example, it's a little tricky because when we read in the data, spaces were turned into periods. There are two periods separating "C.elegans.mean.response" from the concentraion, however, so we can separate using two periods.  

Periods (and some other symbols, like parentheses and square brackets) have special meaning in R, so to tell it to use the periods to separate columns, we have to put two backslashes in front of each period. This is beyond the scope of this workshop so just trust me here. And someday when you run into some issue like this, look up *"regular expressions"*.  

```{r}
tox_cleaned %>% 
    pivot_longer(cols = starts_with("C.elegans.mean.response"), 
                 names_to = c("org", "conc"),
                 names_sep = "\\.\\.",
                 values_to = "response") %>% 
    mutate(conc = str_remove(conc, "\\.uM"))
```



We also want to get rid of the ".uM" at the end of the `conc` column, so I'm using `stringr::str_remove()`. This is another "beyond the scope; just trust me" - but it's useful to see what happens. The cheet sheat for the `stringr` package is helpful in situations like this. ("Regular expressions" are a thing here too.)

```{r}
tox_cleaned %>% 
    pivot_longer(cols = starts_with("C.elegans.mean.response"), 
                 names_to = c("org", "conc"),
                 names_sep = "\\.\\.",
                 values_to = "response") %>% 
    mutate(conc = str_remove(conc, "\\.uM"))
```


If you noticed above, `conc` was still a character after we pivoted. We want to make some graphs, so we need it to be a number. What's different about the code chunk below that made this happen?  

```{r}
tox_long <- tox_cleaned %>% 
    pivot_longer(cols = starts_with("C.elegans.mean.response"), 
                 names_to = c("org", "conc"),
                 names_sep = "\\.\\.",
                 values_to = "response") %>% 
    mutate(conc = str_remove(conc, "\\.uM"),
           conc = as.numeric(conc))
```




```{r}

ggplot(tox_long, aes(x = conc, y = response, color = Name)) +
    geom_point(size = 3)

p <- ggplot(tox_long, aes(x = conc, y = response, color = Name)) +
    geom_point(size = 3)

p +
    facet_wrap(~Name)

p +
    facet_wrap(~Name) +
    scale_x_log10()


# add better axis labels and a title; add a theme; remove the legend because
# the names are at the top of the facets:
q <- p +
    facet_wrap(~Name) +
    scale_x_log10() +
    theme_bw() +
    labs(title = "Toxicity curves for C. elegans",
         x = "concentration (uM)",
         y = "response") +
    theme(legend.position = "none")
q

q + geom_line()
```


You can get more complicated too, by using `pivot_longer_spec()` if you want to keep multiple columns after pivoting (for example, if you had columns for standard deviation in the response in addition to mean response, and wanted to collapse it into `mean_response` and `sd_response` columns for each concentration). Check out `vignette("pivot")` for more details.



## `pivot_wider()`  


The opposite of `pivot_longer()` is `pivot_wider()`. Sometimes you have one observation split over multiple rows, like in a dataset we'll see shortly, and you want to make certain variables be their own columns. To learn how it works, we'll first widen the *C. elegans* dataset back out, and then work on a slightly more complicated dataset.  

```{r}
tox_long %>% 
    pivot_wider(names_from = conc, values_from = response) %>% 
    View()
```

Remember that we'd turned that concentration column into a numeric format, and now numbers are the column names, which R doesn't particularly like. So we might want to combine the organism column with the concentration column, and we can do that by concatinating them in the `names_from` argument:  

```{r}
tox_long %>% 
    pivot_wider(names_from = c(org, conc), values_from = response) %>% 
    View()
```

So with this dataset, we've gone from wide to long, and back again. 


## mini-challenge: reshaping final exam from the slideshow  

```{r}

```


***  
***  
 
